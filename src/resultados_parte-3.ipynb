{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c63cfc43",
   "metadata": {},
   "source": [
    "# Proyecto 1 - Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import linear_regression as lr\t# Implementacion propia de regresion lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f6e24f",
   "metadata": {},
   "source": [
    "## a) Limpieza del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0395155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv('../data/AmesHousing.txt', sep='\\t')\n",
    "\n",
    "# Paso 1: Filtrar solo ventas 'Normales'\n",
    "df = df[df['Sale Condition'] == 'Normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb70b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paso 2: Eliminar propiedades con área habitable > 1500 sq ft\n",
    "df = df[df['Gr Liv Area'] <= 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e40bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: Selección de muestra aleatoria (~200 observaciones)\n",
    "sample_size = min(200, len(df))\n",
    "df_cleaned = df.sample(n=sample_size, random_state=42)\t# se establece una semilla para reproducibilidad\n",
    "\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6942998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el resultado\n",
    "df_cleaned.to_csv('../data/ames_housing_cleaned.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fcb311",
   "metadata": {},
   "source": [
    "## b) Normalización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d4a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso:\n",
    "df = pd.read_csv('../data/ames_housing_cleaned.txt')\n",
    "\n",
    "# 2. Columnas a normalizar\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "to_normalize = [col for col in numeric_cols if col not in ['PID', 'Order', 'Fireplaces']]\n",
    "\n",
    "# 3. Aplicar Z-score\n",
    "for col in to_normalize:\n",
    "\tmean = np.mean(df[col])\n",
    "\tstd = np.std(df[col])\n",
    "\tif std != 0:  # Evitar división por cero\n",
    "\t\tdf[col] = (df[col] - mean) / std\n",
    "\telse:\n",
    "\t\tdf[col] = 0  # Manejar columnas constantes\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89831d86",
   "metadata": {},
   "source": [
    "## c) División Train/Test (80%-20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mezclar el dataset para evitar la división por orden\n",
    "# Se utiliza una semilla para reproducibilidad\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Calcular punto de corte\n",
    "cutoff = int(0.8 * len(df))\n",
    "\n",
    "# Dividir en train y test\n",
    "train_df = df.iloc[:cutoff]\n",
    "test_df = df.iloc[cutoff:]\n",
    "\n",
    "# Separar características y objetivo\n",
    "# Datos de entrenamiento\n",
    "X_train = train_df.drop('SalePrice', axis=1)\n",
    "y_train = train_df['SalePrice']\n",
    "\n",
    "# Datos de prueba\n",
    "X_test = test_df.drop('SalePrice', axis=1)\n",
    "y_test = test_df['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a98d3",
   "metadata": {},
   "source": [
    "## d) Modelos\n",
    "### Modelo 0 - Total Basement + Gr Liv Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355dc6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrenamiento\n",
    "X0_raw_train = X_train[['Total Bsmt SF', 'Gr Liv Area']].values\n",
    "\n",
    "# Datos de prueba\n",
    "X0_raw_test = X_test[['Total Bsmt SF', 'Gr Liv Area']].values\n",
    "\n",
    "# Se mantiene y_test y y_train sin modificacion dado que son los valores objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844448f7",
   "metadata": {},
   "source": [
    "### Modelo 1 - Total Basement + Gr Liv Area + LotArea + Garage Cars + FireYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1320dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame a partir de X_train con la columna FireYN\n",
    "X_train_fireyn = X_train.copy()\n",
    "X_train_fireyn['FireYN'] = X_train_fireyn['Fireplaces'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "# Crear un nuevo DataFrame a partir de X_test con la columna FireYN\n",
    "X_test_fireyn = X_test.copy()\n",
    "X_test_fireyn['FireYN'] = X_test_fireyn['Fireplaces'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrenamiento \n",
    "\n",
    "X1_raw_train = X_train_fireyn[['Total Bsmt SF', 'Gr Liv Area', 'Lot Area', 'Garage Cars', 'FireYN']].values\n",
    "\n",
    "# Datos de prueba\n",
    "X1_raw_test = X_test_fireyn[['Total Bsmt SF', 'Gr Liv Area', 'Lot Area', 'Garage Cars', 'FireYN']].values\n",
    "\n",
    "# Se mantiene y_test y y_train sin modificacion dado que son los valores objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4cbf66",
   "metadata": {},
   "source": [
    "### Modelo 2 - Total Basement + Gr Liv Area + 3 atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b2760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular correlación con SalePrice\n",
    "\n",
    "# Seleccionar solo columnas numéricas\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calcular correlación con SalePrice\n",
    "correlations = numeric_df.corr()['SalePrice'].drop(\n",
    "    ['SalePrice', 'Total Bsmt SF', 'Gr Liv Area', 'Lot Area', 'Garage Cars', 'Fireplaces'],\n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "# Seleccionar los 3 atributos con mayor correlación absoluta\n",
    "top3 = correlations.abs().sort_values(ascending=False).head(3)\n",
    "print(top3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9a0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2 - Total Bsmt SF, Gr Liv Area + 3 atributos con mayor correlación\n",
    "\n",
    "# Obtener los nombres de los 3 atributos seleccionados\n",
    "top3_features = top3.index.tolist()\n",
    "\n",
    "# Datos de entrenamiento\n",
    "X2_raw_train = X_train[['Total Bsmt SF', 'Gr Liv Area'] + top3_features].values\n",
    "\n",
    "# Datos de prueba\n",
    "X2_raw_test = X_test[['Total Bsmt SF', 'Gr Liv Area'] + top3_features].values\n",
    "\n",
    "# Mostrar los nombres de los atributos usados en el modelo 2\n",
    "print(\"Atributos usados en Modelo 2:\", ['Total Bsmt SF', 'Gr Liv Area'] + top3_features)\n",
    "\n",
    "# Eliminar filas con valores vacíos en la columna 'Garage Yr Blt' en los conjuntos de entrenamiento y prueba\n",
    "X2_train_mask = ~X_train[['Garage Yr Blt'] + top3_features].isnull().any(axis=1)\n",
    "X2_test_mask = ~X_test[['Garage Yr Blt'] + top3_features].isnull().any(axis=1)\n",
    "\n",
    "# Filtrar X2_raw_train, X2_raw_test, y los objetivos correspondientes\n",
    "X2_raw_train = X2_raw_train[X2_train_mask.values]\n",
    "y_train_clean = y_train[X2_train_mask]\n",
    "\n",
    "X2_raw_test = X2_raw_test[X2_test_mask.values]\n",
    "y_test_clean = y_test[X2_test_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bf1efb",
   "metadata": {},
   "source": [
    "## e) Evaluación de resultados\n",
    "### Modelo 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac199fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar theta\n",
    "theta = np.zeros(X0_raw_train.shape[1])\n",
    "\n",
    "# Parámetros\n",
    "alpha = 0.0001\n",
    "num_iters = 50000\t# modificacion del valor para controlar las iteraciones\n",
    "\n",
    "# Ejecutar descenso del gradiente\n",
    "theta_final, bias_final, cost_history = lr.gradient_descent(X0_raw_train, y_train, theta, alpha, num_iters)\n",
    "\n",
    "# Predicciones\n",
    "train_predictions = X0_raw_train.dot(theta_final) + bias_final\n",
    "test_predictions = X0_raw_test.dot(theta_final) + bias_final\n",
    "\n",
    "# Métricas de evaluación del modelo (con 5 decimales)\n",
    "# Bias (Avg(prediction - y))\n",
    "metric_bias = np.mean(train_predictions - y_train)\n",
    "metric_bias_test = np.mean(test_predictions - y_test)\n",
    "print(f\"Bias (Train): {metric_bias:.5f}, Bias (Test): {metric_bias_test:.5f}\")\n",
    "\n",
    "# Maximum Deviation (Max|y - prediction|)\n",
    "metric_max_deviation = np.max(np.abs(y_train - train_predictions))\n",
    "metric_max_deviation_test = np.max(np.abs(y_test - test_predictions))\n",
    "print(f\"Maximum Deviation (Train): {metric_max_deviation:.5f}, Maximum Deviation (Test): {metric_max_deviation_test:.5f}\")\n",
    "\n",
    "# Mean Absolute Deviation (Avg|y - prediction|)\n",
    "metric_mean_absolute_deviation = np.mean(np.abs(y_train - train_predictions))\n",
    "metric_mean_absolute_deviation_test = np.mean(np.abs(y_test - test_predictions))\n",
    "print(f\"Mean Absolute Deviation (Train): {metric_mean_absolute_deviation:.5f}, Mean Absolute Deviation (Test): {metric_mean_absolute_deviation_test:.5f}\")\n",
    "\n",
    "# Mean Squared Error (Avg(y - prediction)^2)\n",
    "metric_mean_squared_error = np.mean((y_train - train_predictions) ** 2)\n",
    "metric_mean_squared_error_test = np.mean((y_test - test_predictions) ** 2)\n",
    "print(f\"Mean Squared Error (Train): {metric_mean_squared_error:.5f}, Mean Squared Error (Test): {metric_mean_squared_error_test:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62de9ed",
   "metadata": {},
   "source": [
    "### Modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5383dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar theta\n",
    "theta = np.zeros(X1_raw_train.shape[1])\n",
    "\n",
    "# Parámetros\n",
    "alpha = 0.0001\n",
    "num_iters = 50000\t# modificacion del valor para controlar las iteraciones\n",
    "\n",
    "# Ejecutar descenso del gradiente\n",
    "theta_final, bias_final, cost_history = lr.gradient_descent(X1_raw_train, y_train, theta, alpha, num_iters)\n",
    "\n",
    "# Predicciones\n",
    "train_predictions = X1_raw_train.dot(theta_final) + bias_final\n",
    "test_predictions = X1_raw_test.dot(theta_final) + bias_final\n",
    "\n",
    "# Métricas de evaluación del modelo (con 5 decimales)\n",
    "# Bias (Avg(prediction - y))\n",
    "metric_bias = np.mean(train_predictions - y_train)\n",
    "metric_bias_test = np.mean(test_predictions - y_test)\n",
    "print(f\"Bias (Train): {metric_bias:.5f}, Bias (Test): {metric_bias_test:.5f}\")\n",
    "\n",
    "# Maximum Deviation (Max|y - prediction|)\n",
    "metric_max_deviation = np.max(np.abs(y_train - train_predictions))\n",
    "metric_max_deviation_test = np.max(np.abs(y_test - test_predictions))\n",
    "print(f\"Maximum Deviation (Train): {metric_max_deviation:.5f}, Maximum Deviation (Test): {metric_max_deviation_test:.5f}\")\n",
    "\n",
    "# Mean Absolute Deviation (Avg|y - prediction|)\n",
    "metric_mean_absolute_deviation = np.mean(np.abs(y_train - train_predictions))\n",
    "metric_mean_absolute_deviation_test = np.mean(np.abs(y_test - test_predictions))\n",
    "print(f\"Mean Absolute Deviation (Train): {metric_mean_absolute_deviation:.5f}, Mean Absolute Deviation (Test): {metric_mean_absolute_deviation_test:.5f}\")\n",
    "\n",
    "# Mean Squared Error (Avg(y - prediction)^2)\n",
    "metric_mean_squared_error = np.mean((y_train - train_predictions) ** 2)\n",
    "metric_mean_squared_error_test = np.mean((y_test - test_predictions) ** 2)\n",
    "print(f\"Mean Squared Error (Train): {metric_mean_squared_error:.5f}, Mean Squared Error (Test): {metric_mean_squared_error_test:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1e96e",
   "metadata": {},
   "source": [
    "### Modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b71a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar theta\n",
    "theta = np.zeros(X2_raw_train.shape[1])\n",
    "\n",
    "# Parámetros\n",
    "alpha = 0.0001\n",
    "num_iters = 50000\t# modificacion del valor para controlar las iteraciones\n",
    "\n",
    "# Ejecutar descenso del gradiente\n",
    "theta_final, bias_final, cost_history = lr.gradient_descent(X2_raw_train, y_train_clean, theta, alpha, num_iters)\n",
    "\n",
    "# Predicciones\n",
    "train_predictions = X2_raw_train.dot(theta_final) + bias_final\n",
    "test_predictions = X2_raw_test.dot(theta_final) + bias_final\n",
    "\n",
    "# Métricas de evaluación del modelo (con 5 decimales)\n",
    "# Bias (Avg(prediction - y))\n",
    "metric_bias = np.mean(train_predictions - y_train_clean)\n",
    "metric_bias_test = np.mean(test_predictions - y_test_clean)\n",
    "print(f\"Bias (Train): {metric_bias:.5f}, Bias (Test): {metric_bias_test:.5f}\")\n",
    "\n",
    "# Maximum Deviation (Max|y - prediction|)\n",
    "metric_max_deviation = np.max(np.abs(y_train_clean - train_predictions))\n",
    "metric_max_deviation_test = np.max(np.abs(y_test_clean - test_predictions))\n",
    "print(f\"Maximum Deviation (Train): {metric_max_deviation:.5f}, Maximum Deviation (Test): {metric_max_deviation_test:.5f}\")\n",
    "\n",
    "# Mean Absolute Deviation (Avg|y - prediction|)\n",
    "metric_mean_absolute_deviation = np.mean(np.abs(y_train_clean - train_predictions))\n",
    "metric_mean_absolute_deviation_test = np.mean(np.abs(y_test_clean - test_predictions))\n",
    "print(f\"Mean Absolute Deviation (Train): {metric_mean_absolute_deviation:.5f}, Mean Absolute Deviation (Test): {metric_mean_absolute_deviation_test:.5f}\")\n",
    "\n",
    "# Mean Squared Error (Avg(y - prediction)^2)\n",
    "metric_mean_squared_error = np.mean((y_train_clean - train_predictions) ** 2)\n",
    "metric_mean_squared_error_test = np.mean((y_test_clean - test_predictions) ** 2)\n",
    "print(f\"Mean Squared Error (Train): {metric_mean_squared_error:.5f}, Mean Squared Error (Test): {metric_mean_squared_error_test:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e44080",
   "metadata": {},
   "source": [
    "### Comparacion entre modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3356a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Nombres de las métricas\n",
    "metrics = [\n",
    "    \"Bias\",\n",
    "    \"Maximum Deviation\",\n",
    "    \"Mean Absolute Deviation\",\n",
    "    \"Mean Squared Error\"\n",
    "]\n",
    "\n",
    "# Valores de ejemplo: reemplaza estos valores por los de tus modelos\n",
    "# Cada lista: [Modelo 0, Modelo 1, Modelo 2]\n",
    "train_values = [\n",
    "    [0.12576, 0.11023, 0.09876],   # Bias (Train)\n",
    "    [4.20734, 3.87654, 3.54321],   # Max Deviation (Train)\n",
    "    [0.77744, 0.65432, 0.61234],   # MAE (Train)\n",
    "    [1.06356, 0.98765, 0.87654]    # MSE (Train)\n",
    "]\n",
    "test_values = [\n",
    "    [-0.00318, 0.01234, 0.02345],  # Bias (Test)\n",
    "    [2.51632, 2.34567, 2.12345],   # Max Deviation (Test)\n",
    "    [0.68818, 0.54321, 0.51234],   # MAE (Test)\n",
    "    [0.79456, 0.76543, 0.65432]    # MSE (Test)\n",
    "]\n",
    "\n",
    "model_labels = ['Modelo 0', 'Modelo 1', 'Modelo 2']\n",
    "x = np.arange(len(metrics))  # posiciones de las métricas\n",
    "width = 0.22  # ancho de las barras\n",
    "\n",
    "# --- Gráfica para entrenamiento ---\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i, model in enumerate(model_labels):\n",
    "    ax.bar(x + (i-1)*width, [train_values[j][i] for j in range(len(metrics))], width, label=model)\n",
    "\n",
    "ax.set_ylabel('Valor')\n",
    "ax.set_title('Comparación de métricas de entrenamiento entre modelos')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics, rotation=15)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Gráfica para prueba ---\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i, model in enumerate(model_labels):\n",
    "    ax.bar(x + (i-1)*width, [test_values[j][i] for j in range(len(metrics))], width, label=model)\n",
    "\n",
    "ax.set_ylabel('Valor')\n",
    "ax.set_title('Comparación de métricas de prueba entre modelos')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics, rotation=15)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
